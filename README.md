<div align="center">

![Future AGI Logo](Logo.png)

# Future AGI SDK

**The world's most accurate AI evaluation, observability and optimization platform**

[![PyPI version](https://badge.fury.io/py/futureagi.svg)](https://pypi.org/project/futureagi/)
[![Downloads](https://static.pepy.tech/badge/futureagi)](https://pepy.tech/project/futureagi)
[![Python Support](https://img.shields.io/pypi/pyversions/futureagi.svg)](https://pypi.org/project/futureagi/)
[![License](https://img.shields.io/badge/License-BSD--3--Clause-blue.svg)](LICENSE.md)
[![GitHub Stars](https://img.shields.io/github/stars/future-agi/futureagi-sdk?style=social)](https://github.com/future-agi/futureagi-sdk)

[ğŸ“– Docs](https://docs.futureagi.com) â€¢ [ğŸŒ Website](https://www.futureagi.com) â€¢ [ğŸ’¬ Community](https://www.linkedin.com/company/futureagi) â€¢ [ğŸ¯ Dashboard](https://app.futureagi.com)

</div>

---

## ğŸ“– Table of Contents

- [What is Future AGI?](#-what-is-future-agi)
- [Installation](#-installation)
- [Authentication](#-authentication)
- [30-Second Examples](#-30-second-examples)
- [Quick Start](#-quick-start)
  - [Dataset Management](#-dataset-management)
  - [Prompt Workbench](#-prompt-workbench)
  - [Knowledge Base (RAG)](#-knowledge-base-rag)
- [How It Works](#ï¸-how-it-works)
- [Core Use Cases](#-core-use-cases)
- [Real-World Use Cases](#-real-world-use-cases)
- [Why Choose Future AGI?](#-why-choose-future-agi)
- [Supported Integrations](#-supported-integrations)
- [Documentation](#-documentation)
- [Language Support](#-language-support)
- [Support & Community](#-support--community)
- [Contributing](#-contributing)
- [Testimonials](#-testimonials)
- [Roadmap](#-roadmap)
- [Troubleshooting & FAQ](#-troubleshooting--faq)

---

## ğŸš€ What is Future AGI?

Future AGI empowers GenAI teams to build near-perfect AI applications through comprehensive evaluation, monitoring, and optimization. Our platform provides everything you need to develop, test, and deploy production-ready AI systems with confidence.

```bash
# Get started in 30 seconds
pip install futureagi
export FI_API_KEY="your_key"
export FI_SECRET_KEY="your_secret"
```

**ğŸ‘‰ [Get Free API Keys](https://app.futureagi.com/signup) â€¢ [View Live Demo](https://docs.futureagi.com) â€¢ [Read Quick Start Guide](https://docs.futureagi.com/get-started/quickstart)**

### âœ¨ Key Features

- **ğŸ¯ World-Class Evaluations** â€” Industry-leading evaluation frameworks powered by our Critique AI agent
- **âš¡ Ultra-Fast Guardrails** â€” Real-time safety checks with sub-100ms latency
- **ğŸ“Š Dataset Management** â€” Programmatically create, update, and manage AI training datasets
- **ğŸ¨ Prompt Workbench** â€” Version control, A/B testing, and deployment management for prompts
- **ğŸ“š Knowledge Base** â€” Intelligent document management and retrieval for RAG applications
- **ğŸ“ˆ Advanced Analytics** â€” Deep insights into model performance and behavior
- **ğŸ¤– Simulate your AI system** â€” Simulate your AI system with different scenarios and see how it performs
- **Add Observability** â€” Add observability to your AI system to monitor its performance and behavior


---

## ğŸ“¦ Installation

### Python
```bash
pip install futureagi
```

### TypeScript/JavaScript
```bash
npm install @futureagi/sdk
# or
pnpm add @futureagi/sdk
```

**Requirements:** Python >= 3.6 | Node.js >= 14

---

## ğŸ”‘ Authentication

Get your API credentials from the [Future AGI Dashboard](https://app.futureagi.com):

```bash
export FI_API_KEY="your_api_key"
export FI_SECRET_KEY="your_secret_key"
```

Or set them programmatically:

```python
import os
os.environ["FI_API_KEY"] = "your_api_key"
os.environ["FI_SECRET_KEY"] = "your_secret_key"
```

## ğŸ¯ Quick Start

### ğŸ“Š Dataset Management

Create and manage datasets with built-in evaluations:

```python
from fi.datasets import Dataset
from fi.datasets.types import (
    Cell, Column, DatasetConfig, DataTypeChoices,
    ModelTypes, Row, SourceChoices
)

# Create a new dataset
config = DatasetConfig(name="qa_dataset", model_type=ModelTypes.GENERATIVE_LLM)
dataset = Dataset(dataset_config=config)
dataset = dataset.create()

# Define columns
columns = [
    Column(name="user_query", data_type=DataTypeChoices.TEXT, source=SourceChoices.OTHERS),
    Column(name="ai_response", data_type=DataTypeChoices.TEXT, source=SourceChoices.OTHERS),
    Column(name="quality_score", data_type=DataTypeChoices.INTEGER, source=SourceChoices.OTHERS),
]

# Add data
rows = [
    Row(order=1, cells=[
            Cell(column_name="user_query", value="What is machine learning?"),
        Cell(column_name="ai_response", value="Machine learning is a subset of AI..."),
        Cell(column_name="quality_score", value=9),
    ]),
    Row(order=2, cells=[
            Cell(column_name="user_query", value="Explain quantum computing"),
        Cell(column_name="ai_response", value="Quantum computing uses quantum bits..."),
        Cell(column_name="quality_score", value=8),
    ]),
]

# Push data and run evaluations
    dataset = dataset.add_columns(columns=columns)
    dataset = dataset.add_rows(rows=rows)

# Add automated evaluation
dataset.add_evaluation(
    name="factual_accuracy",
    eval_template="is_factually_consistent",
    required_keys_to_column_names={
        "input": "user_query",
        "output": "ai_response",
        "context": "user_query",
    },
    run=True
)

print("âœ“ Dataset created with automated evaluations")
```

### ğŸ¨ Prompt Workbench

Version control and A/B test your prompts:

```python
from fi.prompt import Prompt, PromptTemplate, ModelConfig

# Create a versioned prompt template
template = PromptTemplate(
    name="customer_support",
    messages=[
        {"role": "system", "content": "You are a helpful customer support agent."},
        {"role": "user", "content": "Help {{customer_name}} with {{issue_type}}."},
    ],
    variable_names={"customer_name": ["Alice"], "issue_type": ["billing"]},
    model_configuration=ModelConfig(model_name="gpt-4o-mini", temperature=0.7)
)

# Create and version the template
client = Prompt(template)
client.create()  # Create v1
client.commit_current_version("Initial version", set_as_default=True)

# Assign deployment labels
client.labels().assign("Production", "v1")

# Compile with variables
compiled = client.compile({"customer_name": "Bob", "issue_type": "refund"})
print(compiled)
# Output: [
#   {"role": "system", "content": "You are a helpful customer support agent."},
#   {"role": "user", "content": "Help Bob with refund."}
# ]
```

**A/B Testing Example:**

```python
import random
from openai import OpenAI
from fi.prompt import Prompt

# Fetch different variants
variant_a = Prompt.get_template_by_name("customer_support", label="variant-a")
variant_b = Prompt.get_template_by_name("customer_support", label="variant-b")

# Randomly select and use
selected = random.choice([variant_a, variant_b])
client = Prompt(selected)
compiled = client.compile({"customer_name": "Alice", "issue_type": "refund"})

# Send to your LLM provider
openai = OpenAI(api_key="your_openai_key")
response = openai.chat.completions.create(model="gpt-4o", messages=compiled)
print(f"Using variant: {selected.version}")
print(f"Response: {response.choices[0].message.content}")
```

### ğŸ“š Knowledge Base (RAG)

Manage documents for retrieval-augmented generation:

```python
from fi.kb import KnowledgeBase

# Initialize client
kb_client = KnowledgeBase(
    fi_api_key="your_api_key",
    fi_secret_key="your_secret_key"
)

# Create a knowledge base with documents
kb = kb_client.create_kb(
    name="product_docs",
    file_paths=["manual.pdf", "faq.txt", "guide.md"]
)

print(f"âœ“ Knowledge base created: {kb.kb.name}")
print(f"  Files uploaded: {len(kb.kb.file_names)}")

# Update with more files
updated_kb = kb_client.update_kb(
    kb_id=kb.kb.id,
    file_paths=["updates.pdf"]
)

# Delete specific files
kb_client.delete_files_from_kb(file_ids=["file_id_here"])

# Clean up
kb_client.delete_kb(kb_ids=[kb.kb.id])
```

## ğŸ¯ Core Use Cases

| Feature | Use Case | Benefit |
|---------|----------|---------|
| **Datasets** | Store and version training/test data | Reproducible experiments, automated evaluations |
| **Prompt Workbench** | Version control for prompts | A/B testing, deployment management, rollback |
| **Knowledge Base** | Evaluations and synthetic data | Intelligent retrieval, document versioning |
| **Evaluations** | Automated quality checks | No human-in-the-loop, 100% configurable |
| **Protect** | Real-time safety filters | Sub-100ms latency, production-ready |

---

## ğŸ”¥ Why Choose Future AGI?

| Feature | Future AGI | Traditional Tools | Other Platforms |
|---------|-----------|-------------------|-----------------|
| **Evaluation Speed** | âš¡ Sub-100ms | ğŸŒ Seconds-Minutes | ğŸ¢ Minutes-Hours |
| **Human in Loop** | âŒ Fully Automated | âœ… Required | âœ… Often Required |
| **Multimodal Support** | âœ… Text, Image, Audio, Video | âš ï¸ Limited | âš ï¸ Text Only |
| **Setup Time** | â±ï¸ 2 minutes | â³ Days-Weeks | â³ Hours-Days |
| **Configurability** | ğŸ¯ 100% Customizable | ğŸ”’ Fixed Metrics | âš™ï¸ Some Flexibility |
| **Privacy Options** | ğŸ” Cloud + Self-hosted | â˜ï¸ Cloud Only | â˜ï¸ Cloud Only |
| **A/B Testing** | âœ… Built-in | âŒ Manual | âš ï¸ Limited |
| **Prompt Versioning** | âœ… Git-like Control | âŒ Not Available | âš ï¸ Basic |
| **Real-time Guardrails** | âœ… Production-ready | âŒ Not Available | âš ï¸ Experimental |

---

## ğŸ”Œ Supported Integrations

Future AGI works seamlessly with your existing AI stack:

**LLM Providers**  
`OpenAI` â€¢ `Anthropic` â€¢ `Google Gemini` â€¢ `Azure OpenAI` â€¢ `AWS Bedrock` â€¢ `Cohere` â€¢ `Mistral` â€¢ `Ollama`

**Frameworks**  
`LangChain` â€¢ `LlamaIndex` â€¢ `CrewAI` â€¢ `AutoGen` â€¢ `Haystack` â€¢ `Semantic Kernel`

**Vector Databases**  
`Pinecone` â€¢ `Weaviate` â€¢ `Qdrant` â€¢ `Milvus` â€¢ `Chroma` â€¢ `FAISS` â€¢ `vLLM`

**Observability**  
`OpenTelemetry` â€¢ `Custom Logging` â€¢ `Trace Context Propagation`

---

## ğŸ“š Documentation

- **[Complete Documentation](https://docs.futureagi.com)**
- **[Dataset SDK Guide](https://docs.futureagi.com/future-agi/get-started/dataset/adding-dataset/using-sdk)**
- **[Prompt Workbench Guide](https://docs.futureagi.com/products/prompt/how-to/prompt-workbench-using-sdk)**
- **[Knowledge Base Guide](https://docs.futureagi.com/future-agi/get-started/knowledge-base/how-to/create-kb-using-sdk)**
- **[API Reference](https://docs.futureagi.com)**

---

## ğŸ¤ Language Support

| Language | Package | Status |
|----------|---------|--------|
| **Python** | `futureagi` | âœ… Full Support |
| **TypeScript/JavaScript** | `@futureagi/sdk` | âœ… Full Support |
| **REST API** | cURL/HTTP | âœ… Available |

---

## ğŸ†˜ Support & Community

- **ğŸ“§ Email:** support@futureagi.com
- **ğŸ’¼ LinkedIn:** [Future AGI Company](https://www.linkedin.com/company/futureagi)
- **ğŸ¦ X (Twitter):** [@FutureAGI_](https://x.com/FutureAGI_)
- **ğŸ“° Substack:** [Future AGI Blog](https://substack.com/@futureagi)

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get involved:

- **ğŸ› Report bugs**: [Open an issue](https://github.com/future-agi/futureagi-sdk/issues)
- **ğŸ’¡ Request features**: [Start a discussion](https://github.com/future-agi/futureagi-sdk/discussions)
- **ğŸ”§ Submit PRs**: Fork, create a feature branch, and submit a pull request
- **ğŸ“– Improve docs**: Help us make our documentation better

See [CONTRIBUTING.md](https://github.com/future-agi/futureagi-sdk/blob/main/CONTRIBUTING.md) for detailed guidelines.

---

## ğŸŒŸ Testimonials

> "Future AGI cut our evaluation time from days to minutes. The automated critiques are spot-on!"  
> â€” **AI Engineering Team, Fortune 500 Company**

> "The prompt versioning alone saved us countless headaches. A/B testing is now trivial."  
> â€” **ML Lead, Healthcare Startup**

> "Sub-100ms guardrails in production. Game changer for our customer-facing AI."  
> â€” **CTO, E-commerce Platform**

---

## ğŸ“Š Roadmap

- [x] Datasets with automated evaluations
- [x] Prompt workbench with versioning
- [x] Knowledge base for RAG
- [x] Real-time guardrails (sub-100ms)
- [x] Multi-language SDK (Python + TypeScript)
- [x] Bulk Annotations for Human in the Loop
- [ ] On-premise deployment toolkit

---

## â“ Troubleshooting & FAQ

<details>
<summary><strong>Import Error: `ModuleNotFoundError: No module named 'fi'`</strong></summary>

Make sure Future AGI is installed:
```bash
pip install futureagi --upgrade
```
</details>

<details>
<summary><strong>Authentication Error: Invalid API credentials</strong></summary>

1. Check your API keys at [Dashboard](https://app.futureagi.com/settings/api-keys)
2. Ensure environment variables are set correctly:
```bash
echo $FI_API_KEY
echo $FI_SECRET_KEY
```
3. Try setting them programmatically in your code
</details>

<details>
<summary><strong>How do I switch between environments (dev/staging/prod)?</strong></summary>

Use prompt labels to manage different deployment environments:
```python
client.labels().assign("Development", "v1")
client.labels().assign("Staging", "v2")
client.labels().assign("Production", "v3")
```
</details>

<details>
<summary><strong>Can I use Future AGI without sending data to the cloud?</strong></summary>

Yes! Future AGI supports self-hosted deployments. Contact us at support@futureagi.com for enterprise on-premise options.
</details>

<details>
<summary><strong>What LLM providers are supported?</strong></summary>

All major providers: OpenAI, Anthropic, Google, Azure, AWS Bedrock, Cohere, Mistral, and open-source models via vLLM/Ollama.
</details>

**Need more help?** Check our [complete FAQ](https://docs.futureagi.com/faq) or [join our community](https://www.linkedin.com/company/futureagi).

---

## ğŸ“„ License

This project is licensed under the BSD-3-Clause License - see the [LICENSE.md](LICENSE.md) file for details.

---

<div align="center">

## ğŸš€ Ready to Build Better AI?

**[ğŸ¯ Get Free API Keys](https://app.futureagi.com/signup)** â€¢ **[ğŸ“– Read the Docs](https://docs.futureagi.com)** â€¢ **[ğŸ’¬ Join Community](https://www.linkedin.com/company/futureagi)**

---

### â­ If you find Future AGI helpful, give us a star on GitHub!

[![Star History Chart](https://api.star-history.com/svg?repos=future-agi/futureagi-sdk&type=Date)](https://star-history.com/#future-agi/futureagi-sdk&Date)

---

Made with â¤ï¸ by the [Future AGI Team](https://www.futureagi.com)

**[Website](https://www.futureagi.com)** â€¢ **[Documentation](https://docs.futureagi.com)** â€¢ **[Dashboard](https://app.futureagi.com)** â€¢ **[Blog](https://substack.com/@futureagi)** â€¢ **[Twitter](https://x.com/FutureAGI_)**

Â© 2025 Future AGI. All rights reserved.

</div>
